---
title: "falcon 설치해 보기 추천 싸이트 "
excerpt_separator: "<!--more-->"
categories:
  - AI
tags:
  - falcon

toc : true
toc_sticky : true
---

# falcon설치 해보기
[falcon huggingface](https://huggingface.co/tiiuae/falcon-40b)  

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model = "tiiuae/falcon-40b"

tokenizer = AutoTokenizer.from_pretrained(model)
pipeline = transformers.pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    device_map="auto",
)
sequences = pipeline(
   "Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\nDaniel: Hello, Girafatron!\nGirafatron:",
    max_length=200,
    do_sample=True,
    top_k=10,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
)
for seq in sequences:
    print(f"Result: {seq['generated_text']}")

```

## install package
pip install transformers  
pip install torch  
pip install einops    
pip install accelerate
pip install xformers

## 실행
실행하면 model을 받고 실행된다.    
<img width="1432" alt="image" src="https://github.com/younlea/younlea.github.io/assets/1435846/ea49f0e3-7794-40c8-ac1a-16a082d827b1">
에러가 발생하는데 좀더 해보자    
[error discussion](https://huggingface.co/tiiuae/falcon-40b/discussions/3)    
훔.. 메모리가 충분하지 않아서 그런지 ㅜㅜ   다른 방법을 찾아보자...   
참고로 현재 사용하는 GPU는 4070 ti임   
