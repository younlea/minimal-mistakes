---
title: "langchain 과 llm을 이용해서 무언가(?) 만들기 "
excerpt_separator: "<!--more-->"
categories:
  - AI
tags:
  - langchain

toc : true
toc_sticky : true
---

# langchain
LLM model's framework   
![image](https://github.com/younlea/younlea.github.io/assets/1435846/07866216-9754-4b95-a517-39ec61fd53a8)

[langchain homepage](https://www.langchain.com/)    
[langchain python](https://python.langchain.com/docs/get_started/introduction)    
[langchain github](https://github.com/langchain-ai/langchain)     

## local llm model 
[https://python.langchain.com/docs/guides/local_llms](https://python.langchain.com/docs/guides/local_llms)     

## opengpts
[https://github.com/langchain-ai/opengpts](https://github.com/langchain-ai/opengpts)    

# streamlit.io (frontend)  
[https://streamlit.io/](https://streamlit.io/)    

# LLAMA2
[LLAMA2 homepage](https://ai.meta.com/llama/)    
[경량화 LLAMA2](https://huggingface.co/TheBloke/Llama-2-7B-GGML)     

## ctransformers
경량화 llama2를 쓰기 위해 필요함
[https://github.com/marella/ctransformers](https://github.com/marella/ctransformers)    

## llama2 chatgpt처럼 쓰기
[https://labs.perplexity.ai/](https://labs.perplexity.ai/)     

## ai 사용 관련 참고 
[https://wikidocs.net](https://wikidocs.net/208922)      

# 직접 만들기
llama2 down받기 (llama-2-7b.ggmlv3.q8_0.bin)      
pip install langchain
pip install ctransformers   

## source code 
```python
from langchain.llms import CTransformers

llm = CTransformers(
  model="llama-2-7b.ggmlv3.q8_0.bin",
  model_type="llama"
)

result = llm.predict("what do you name?")
print(result)

```
